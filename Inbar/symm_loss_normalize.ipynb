{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6eb6ea-6dd0-4167-b600-236b8ff669aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import grad\n",
    "import einops\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "from symm_loss_defs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbf8f0bb-d505-4eea-bcce-32432db164c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymmLoss_norm(nn.Module):\n",
    "\n",
    "    def __init__(self, gens_list,model,device = devicef):\n",
    "        super(SymmLoss_norm, self).__init__()\n",
    "        \n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        # Initialize generators (in future add different reps for inputs?)\n",
    "        self.generators = einops.rearrange(gens_list, 'n w h -> n w h')\n",
    "        self.generators = self.generators.to(device)\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, input, model_rep='scalar',norm = \"none\"):\n",
    "        \n",
    "        input = input.clone().detach().requires_grad_(True)\n",
    "        input = input.to(self.device)\n",
    "        # Compute model output, shape [B]\n",
    "        output = self.model(input)\n",
    "\n",
    "        # Compute gradients with respect to input, shape [B, d*N], B is the batch size, d is the input irrep dimension, N is the number of particles\n",
    "        grads, = torch.autograd.grad(outputs=output, inputs=input, grad_outputs=torch.ones_like(output, device=self.device), create_graph=True)\n",
    "        \n",
    "        grads_norm = torch.einsum('... N, ... N -> ...', grads, grads)\n",
    "        print(grads_norm.mean())\n",
    "        \n",
    "        # Reshape grads to [B, N, d] \n",
    "        grads = einops.rearrange(grads, '... (N d) -> ... N d',d = self.generators.shape[-1])\n",
    "\n",
    "        # Contract grads with generators, shape [n (generators), B, N, d]\n",
    "        gen_grads = torch.einsum('n h d, ... N h->  n ... N d ',self.generators, grads)\n",
    "        # Reshape to [n, B, (d N)]\n",
    "        gen_grads = einops.rearrange(gen_grads, 'n ... N d -> n ... (N d)')\n",
    "\n",
    "        # Dot with input [n ,B]\n",
    "        differential_trans = torch.einsum('n ... N, ... N -> n ...', gen_grads, input)\n",
    "        \n",
    "       \n",
    "        \n",
    "        scalar_loss = (differential_trans ** 2).mean()\n",
    "        print(f\"symm loss = {scalar_loss}\")\n",
    "        \n",
    "        scalar_loss_norm = (1/len(self.generators))*(torch.sum(differential_trans**2,dim = 0)/grads_norm).mean()\n",
    "     \n",
    "            \n",
    "        return scalar_loss_norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc56674-8190-4074-b8d7-839220d42989",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dinput = 4\n",
    "N = 100\n",
    "norm = 1\n",
    "\n",
    "train_data = (torch.rand(N,dinput)-0.5)*norm\n",
    "train_dataset = TensorDataset(train_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=N, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953d35fb-18ce-443b-8d59-9c685f702164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mymodelLorentz = inv_model(dinput = 4, init = \"eta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1975342b-24c7-4d47-be83-69fd4863480e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lossLorentz = SymmLoss(gens_list=gens_Lorentz, model = mymodelLorentz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d596ff1-9b37-40e7-8783-69802fb5f53c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_res = lossLorentz(input = train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "163066ee-67ca-4499-8220-f6c9f6f7c45e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.5106e-18, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a5ea791-6570-4d09-b349-178b241408f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lossLorentzNorm = SymmLoss_norm(gens_list=gens_Lorentz, model = mymodelLorentz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d043af0f-5cd1-4346-8c6b-2a1096e340fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symm loss = 5.510590386863952e-18\n"
     ]
    }
   ],
   "source": [
    "loss_res_norm = lossLorentzNorm(input = train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1da40f1d-0fbc-4364-835e-2c0086074d82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3546e-18, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_res_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
