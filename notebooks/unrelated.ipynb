{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "class simplenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simplenet,self).__init__()\n",
    "        self.vecs=nn.Parameter(torch.randn([12],requires_grad=True))\n",
    "        \n",
    "    \n",
    "    def forward(self):\n",
    "        a,b,c,d=self.vecs.chunk(4)\n",
    "        return torch.einsum('i,j->ij',a,b)+torch.einsum('i,j->ij',c,d)\n",
    "    \n",
    "\n",
    "class simplernet(nn.Module):\n",
    "    def __init__(self,n):\n",
    "        super(simplernet,self).__init__()\n",
    "        self.a=nn.Parameter(torch.randn([n],requires_grad=True)/1.0)\n",
    "        self.b=nn.Parameter(torch.randn([n],requires_grad=True)/1.0)\n",
    "        self.c=nn.Parameter(torch.randn([n],requires_grad=True)/1.0)\n",
    "        self.d=nn.Parameter(torch.randn([n],requires_grad=True)/1.0)\n",
    "        \n",
    "    \n",
    "    def forward(self):\n",
    "        return torch.einsum('i,j->ij',self.a,self.b)+torch.einsum('i,j->ij',self.c,self.d)\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class biggerNet(nn.Module):\n",
    "    def __init__(self,dim,num):\n",
    "        super(biggerNet,self).__init__()\n",
    "        self.cols=nn.Parameter(torch.randn([num,dim],requires_grad=True,dtype=torch.float32)/math.sqrt(num))\n",
    "        self.rows=nn.Parameter(torch.randn([num,dim],requires_grad=True,dtype=torch.float32)/math.sqrt(num))\n",
    "\n",
    "    def forward(self):\n",
    "        outer=torch.einsum('ij, ik -> ijk',self.cols,self.rows)\n",
    "        return outer.sum(dim=0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26230884, 0.3357203 , 0.2036532 , 0.39317602, 0.34981224,\n",
       "       0.23194468, 0.35149246, 0.2701878 , 0.28628075, 0.55980575,\n",
       "       0.3431646 , 0.1895501 , 0.20602353, 0.48316655, 0.3648572 ,\n",
       "       0.45552692, 0.10852868, 0.41295424, 0.6547695 , 0.2648464 ],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=biggerNet(3,20)\n",
    "model()\n",
    "(model.rows.norm(2,dim=1)*model.cols.norm(2,dim=1)).sqrt().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30000\t|\tloss: -12.38\t|\tnorms: [ 0.3  0.1  0.3  0.3  0.2  0.4  0.2 -0.3 -0.2  0.2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange,tqdm\n",
    "torch.manual_seed(7923)\n",
    "\n",
    "model=biggerNet(12,10)\n",
    "\n",
    "K=torch.randn([12,1],requires_grad=False)\n",
    "Q=torch.randn([12,1],requires_grad=False)\n",
    "Teach=Q @ K.T\n",
    "\n",
    "K=torch.randn([12,1],requires_grad=False)\n",
    "Q=torch.randn([12,1],requires_grad=False)\n",
    "\n",
    "Teach += Q @ K.T\n",
    "\n",
    "optimizer=torch.optim.AdamW(model.parameters(),lr=0.05,weight_decay=0*1e-1,amsgrad=True)\n",
    "\n",
    "epochs=30000\n",
    "\n",
    "\n",
    "norm_arr=[]\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss=torch.norm(model()-Teach,2)**2\n",
    "    # print(loss)\n",
    "    # loss+=0.01*torch.norm(model.vecs,1)\n",
    "    # norms=torch.norm(model.vecs.view(4,3),2,dim=1).view(2,2).prod(dim=1).sqrt()\n",
    "    # norms=[(model.a.norm()*model.b.norm()),(model.c.norm()*model.d.norm())]\n",
    "    # norms=[(model.b.norm()),(model.d.norm())]\n",
    "    # loss+=0.1* torch.tensor(norms).sum()\n",
    "    norms=(model.rows.norm(2,dim=1)*model.cols.norm(2,dim=1)).sqrt().detach().numpy()\n",
    "    norm_arr.append(norms)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    if (epoch+1)%30000==0:\n",
    "        print(f'epoch: {epoch+1}\\t|\\tloss: {loss.log10().item():.2f}\\t|\\tnorms: '+np.array2string(np.log10(norms), precision=1, floatmode='fixed'))#\\t|\\tnorms: {norms[0]:.2f}, {norms[1]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for line in np.array(norm_arr).T:\n",
    "    plt.plot(line)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Norms')\n",
    "# plt.ylim(1e-5,10)\n",
    "plt.xlim(0,20000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "           -inf,    -inf, -7.2247, -7.2247, -7.2247, -7.2247, -7.2247, -7.2247,\n",
       "        -7.2247, -7.2247, -7.2247, -7.2247, -7.2247, -7.2247, -7.2247, -7.2247,\n",
       "        -7.2247, -6.9237, -6.9237, -6.9237, -6.9237, -6.9237, -6.9237, -6.9237,\n",
       "        -6.9237, -6.9237, -6.9237, -6.9237, -6.9237, -6.9237, -6.9237, -6.9237,\n",
       "        -6.9237, -6.9237, -6.9237, -6.9237, -6.9237, -6.9237, -6.9237, -6.9237,\n",
       "        -6.9237, -6.9237, -6.9237, -6.9237, -6.9237, -6.9237, -6.9237, -6.9237,\n",
       "        -6.9237, -6.9237, -6.7476, -6.7476, -6.7476, -6.7476, -6.6227, -6.6227,\n",
       "        -6.6227, -6.6227, -6.5257, -6.4466, -6.4466, -6.4466, -6.4466, -6.3796,\n",
       "        -6.3216, -6.2247, -6.1833, -6.1833, -6.1455, -5.9237, -5.4844, -5.4765])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(1-model().detach()/Teach).abs().log10().view(-1).sort().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class short(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(short,self).__init__()\n",
    "        self.y=nn.Parameter(torch.randn([1],requires_grad=True,dtype=torch.double))\n",
    "        self.x=nn.Parameter(torch.randn([1],requires_grad=True,dtype=torch.double))\n",
    "       \n",
    "        self.t1=nn.Parameter(torch.randn([1],requires_grad=True,dtype=torch.double))\n",
    "        self.t2=nn.Parameter(torch.randn([1],requires_grad=True,dtype=torch.double))\n",
    "        self.q1=nn.Parameter(torch.randn([1],requires_grad=True,dtype=torch.double))\n",
    "        self.q2=nn.Parameter(torch.randn([1],requires_grad=True,dtype=torch.double))\n",
    "        \n",
    "    \n",
    "    def forward(self,input):\n",
    "        T1=torch.cos(self.t1)\n",
    "        T2=torch.cos(self.t2)\n",
    "        Q1=torch.cos(self.q1)\n",
    "        Q2=torch.cos(self.q2)\n",
    "\n",
    "        T12=torch.cos(self.t1-self.t2)\n",
    "        Q12=torch.cos(self.q1-self.q2)\n",
    "\n",
    "        return 1+self.x**2+self.y**2-2*self.x*T1*Q1-2*self.y*T2*Q2+2*self.x*self.y*T12*Q12\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n",
      "1.0848221364009287\n"
     ]
    }
   ],
   "source": [
    "model=short()\n",
    "\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr= 10)\n",
    "\n",
    "for i in range(20):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss=model(1).sum()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y -4.382595385615131 -0.011813331989359764\n",
      "x -11.365170701502864 -0.04147588133806347\n",
      "t1 -0.12328021247151669 0.27765189142157204\n",
      "t2 -0.13743348349124382 1.2311498137139976\n",
      "q1 -0.17087148749312517 0.3617193944205535\n",
      "q2 0.0057330334781476155 -0.09005317162602089\n"
     ]
    }
   ],
   "source": [
    "# model=short()\n",
    "model.train()\n",
    "loss=model(None).sum()\n",
    "loss.backward()\n",
    "oprimizer.step()\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.grad.item(), param.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0232\n",
      "0.019000000000000156\n",
      "0.014736000000000067\n",
      "0.013224000000000154\n",
      "0.011688959999999776\n",
      "0.011144639999999923\n",
      "0.010592025600000433\n",
      "0.010396070400000084\n",
      "0.010197129215999743\n",
      "0.010126585344000003\n",
      "0.01005496651776015\n",
      "0.010029570723840135\n",
      "0.01000378794639368\n",
      "0.00999464546058247\n",
      "0.009985363660701527\n",
      "0.009982072365809756\n",
      "0.009978730917852601\n",
      "0.00997754605169131\n",
      "0.009976343130426862\n",
      "0.009975916578609145\n",
      "0.00997548352695359\n",
      "0.009975329968299234\n",
      "0.009975174069703498\n",
      "0.009975118788587672\n",
      "0.009975062665093109\n",
      "0.009975042763891698\n",
      "0.00997502255943356\n",
      "0.009975015395000956\n",
      "0.009975008121396118\n",
      "0.009975005542200327\n",
      "0.009975002923702575\n",
      "0.009975001995192018\n",
      "0.009975001052533008\n",
      "0.009975000718269168\n",
      "0.009975000378911842\n",
      "0.00997500025857712\n",
      "0.00997500013640826\n",
      "0.00997500009308744\n",
      "0.009975000049106892\n",
      "0.00997500003351165\n",
      "0.009975000017678506\n",
      "0.00997500001206409\n",
      "0.009975000006364433\n",
      "0.009975000004343057\n",
      "0.009975000002291082\n",
      "0.009975000001563546\n",
      "0.009975000000824748\n",
      "0.00997500000056271\n",
      "0.009975000000296903\n",
      "0.009975000000202662\n",
      "0.009975000000106983\n",
      "0.009975000000072915\n",
      "0.009975000000038465\n",
      "0.009975000000026312\n",
      "0.009975000000013773\n",
      "0.009975000000009613\n",
      "0.009975000000005004\n",
      "0.009975000000003254\n",
      "0.009975000000001946\n",
      "0.009975000000001158\n",
      "0.009975000000000676\n",
      "0.009975000000000558\n",
      "0.00997500000000018\n",
      "0.009975000000000242\n",
      "0.009975000000000076\n",
      "0.009975000000000067\n",
      "0.009975000000000062\n",
      "0.00997499999999988\n",
      "0.00997499999999997\n",
      "0.009975000000000038\n",
      "0.009974999999999956\n",
      "0.009975000000000043\n",
      "0.009974999999999862\n",
      "0.009974999999999868\n",
      "0.009975000000000116\n",
      "0.009975000000000032\n",
      "0.009974999999999913\n",
      "0.009974999999999862\n",
      "0.009975000000000012\n",
      "0.00997499999999985\n",
      "0.009974999999999986\n",
      "0.009975000000000065\n",
      "0.00997499999999988\n",
      "0.009974999999999927\n",
      "0.00997499999999986\n",
      "0.009974999999999979\n",
      "0.009975000000000026\n",
      "0.009975000000000008\n",
      "0.009974999999999993\n",
      "0.009975000000000116\n",
      "0.009975000000000062\n",
      "0.009975000000000133\n",
      "0.009975000000000149\n",
      "0.009975000000000013\n",
      "0.009975000000000154\n",
      "0.009974999999999984\n",
      "0.00997499999999998\n",
      "0.009974999999999925\n",
      "0.009974999999999876\n",
      "0.00997499999999999\n",
      "0.00997500000000013\n",
      "0.009975000000000149\n",
      "0.009975000000000145\n",
      "0.00997500000000011\n",
      "0.009975000000000107\n",
      "0.009974999999999998\n",
      "0.00997500000000004\n",
      "0.00997499999999993\n",
      "0.009974999999999913\n",
      "0.009974999999999935\n",
      "0.009975000000000013\n",
      "0.009975000000000114\n",
      "0.009975000000000029\n",
      "0.009974999999999956\n",
      "0.009975000000000128\n",
      "0.00997499999999986\n",
      "0.009975000000000053\n",
      "0.009975000000000026\n",
      "0.009975000000000008\n",
      "0.009974999999999993\n",
      "0.009974999999999982\n",
      "0.009974999999999973\n",
      "0.009974999999999967\n",
      "0.009974999999999961\n",
      "0.009974999999999956\n",
      "0.009974999999999953\n",
      "0.00997499999999995\n",
      "0.00997499999999995\n",
      "0.00997499999999995\n",
      "0.009974999999999946\n",
      "0.009974999999999946\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n",
      "0.009975000000000166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor(0.9950, dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor(-2.4672e-17, dtype=torch.float64, requires_grad=True))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Short(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Short, self).__init__()\n",
    "        self.y = nn.Parameter(torch.tensor(0.01, requires_grad=True, dtype=torch.double))#nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.double))\n",
    "        self.x = nn.Parameter(torch.tensor(1.1, requires_grad=True, dtype=torch.double))#nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.double)/100)\n",
    "        self.t1 = nn.Parameter(torch.tensor(0, requires_grad=True, dtype=torch.double))\n",
    "        self.t2 = nn.Parameter(torch.tensor(0, requires_grad=True, dtype=torch.double))\n",
    "        self.q1 = nn.Parameter(torch.tensor(0, requires_grad=True, dtype=torch.double))\n",
    "        self.q2 = nn.Parameter(torch.tensor(0, requires_grad=True, dtype=torch.double))\n",
    "        \n",
    "    def forward(self):\n",
    "        T1 = torch.cos(self.t1)\n",
    "        T2 = torch.cos(self.t2)\n",
    "        Q1 = torch.cos(self.q1)\n",
    "        Q2 = torch.cos(self.q2)\n",
    "        T12 = torch.cos(self.t1 - self.t2)\n",
    "        Q12 = torch.cos(self.q1 - self.q2)\n",
    "        return 1 + self.x**2 + self.y**2 - 2 * self.x.abs() * T1 * Q1 - 2 * self.y.abs() * T2 * Q2 + 2 * self.x.abs() * self.y.abs() * T12 * Q12\n",
    "    \n",
    "\n",
    "model = Short()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)  # Consider reducing the learning rate\n",
    "\n",
    "for i in range(1000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = model().sum()  # Changed to call the forward method without an argument\n",
    "    loss+= (model.x.abs().sum()+model.y.abs().sum())/100\n",
    "    \n",
    "    loss.backward()  # This is necessary to compute the gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i+1)%100:\n",
    "        print(loss.item())\n",
    "\n",
    "\n",
    "model.x,model.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tn=torch.zeros([2,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorentz_gens=torch.zeros([6,4,4], dtype=torch.float32)\n",
    "sig_mat=torch.tensor([[0,-1],[1,0]],requires_grad=False, dtype=torch.float32).view(-1)\n",
    "\n",
    "# Rotations\n",
    "lorentz_gens[0,[2,2,3,3],[2,3,2,3]]=sig_mat\n",
    "lorentz_gens[1,[3,3,1,1],[3,1,3,1]]=sig_mat\n",
    "lorentz_gens[2,[1,1,2,2],[1,2,1,2]]=sig_mat\n",
    "\n",
    "# Bosts\n",
    "lorentz_gens[3,[0,0,1,1],[0,1,0,1]]=sig_mat.abs()\n",
    "lorentz_gens[4,[0,0,2,2],[0,2,0,2]]=sig_mat.abs()\n",
    "lorentz_gens[5,[0,0,3,3],[0,3,0,3]]=sig_mat.abs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(11.2790, grad_fn=<PowBackward0>),\n",
       " tensor(11.2790, grad_fn=<SumBackward0>),\n",
       " tensor(11.2790, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create an example input tensor of shape [d, e, f]\n",
    "# inputs = torch.randn(2, 3, 4, requires_grad=True)\n",
    "\n",
    "torch.norm(inputs.view(-1),2)**2, (inputs**2).sum(), (torch.norm(inputs,2,dim=-1)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import grad\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append('../python')\n",
    "\n",
    " \n",
    "from Lorentz_loss import LorentzLoss\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "import einops\n",
    "\n",
    "class LorentzInvariantModel(nn.Module):\n",
    "    \"\"\"A simple model that outputs a Lorentz scalar x^T  x.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(LorentzInvariantModel, self).__init__()\n",
    "        # Minkowski metric \n",
    "        self.eta = torch.tensor([1, -1, -1, -1], dtype=torch.float32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape x to [B, N, 4] where N is number of 4-vectors\n",
    "        x = einops.rearrange(x, 'B (N d) -> B N d', d=4)\n",
    "        # Compute x_i^T  x_j for each 4-vector\n",
    "        return torch.einsum('B n i, i, B k i -> B n k', x, self.eta, x).view(x.shape[0],-1).prod(dim=1)\n",
    "\n",
    "# Initialize the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model\n",
    "model = LorentzInvariantModel().to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.9026e+02, -1.2128e-02, -8.2789e-04,  1.0567e+01,  2.9529e+01,\n",
      "         6.3967e+00, -6.8485e-01,  1.9221e+00, -1.3382e+00, -1.2791e+00])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LorentzLoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(model(test_input))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Lorentz loss instance for scalar output\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m lorentz_loss \u001b[38;5;241m=\u001b[39m \u001b[43mLorentzLoss\u001b[49m(device\u001b[38;5;241m=\u001b[39mdevice, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m      9\u001b[0m test_input\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Compute Lorentz loss for scalar case\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LorentzLoss' is not defined"
     ]
    }
   ],
   "source": [
    "# Test input tensor (Batch size = 2, each input is 4-dimensional, 2 particles)\n",
    "test_input = torch.randn([10,8], dtype=torch.float32, device=device)\n",
    "print(model(test_input))\n",
    "\n",
    "# Lorentz loss instance for scalar output\n",
    "            zz = LorentzLoss(device=device, model=model)\n",
    "\n",
    "\n",
    "test_input.requires_grad = True\n",
    "\n",
    "# Compute Lorentz loss for scalar case\n",
    "loss = lorentz_loss(test_input, spin='scalar')\n",
    "\n",
    "print(\"Lorentz Scalar Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 1]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3,4]\n",
    "a[1:]+a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(''[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A 4 vector try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(self,d_in,d_out,bias=True):\n",
    "        super(block,self).__init__()\n",
    "        self.fc = nn.Linear(d_in,d_out,bias=bias)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        return(x)\n",
    "\n",
    "class CrazyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrazyModel,self).__init__()\n",
    "\n",
    "        self.blocks = nn.Sequential(\n",
    "            block(4,10),\n",
    "            block(10,10),\n",
    "            block(10,10),\n",
    "            block(10,1),\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        return self.blocks(x)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_val(tensor):\n",
    "    # assume shape [B,N,4]\n",
    "    eta = torch.tensor([1, -1, -1, -1])\n",
    "    xx= torch.einsum('B N i, i ,B N i -> B N',tensor,eta,tensor)\n",
    "\n",
    "    return (xx + xx**2/4)/math.sqrt(21)\n",
    "\n",
    "data = torch.randn([1,100000,4])\n",
    "labels = scalar_val(data)\n",
    "\n",
    "model=CrazyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0\t|\tloss:0.9897177219390869\n",
      "iter:100\t|\tloss:0.9897177219390869\n",
      "iter:200\t|\tloss:0.9897177219390869\n",
      "iter:300\t|\tloss:0.9897177219390869\n",
      "iter:400\t|\tloss:0.9897177219390869\n",
      "iter:500\t|\tloss:0.9897177219390869\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m out \u001b[38;5;241m=\u001b[39m loss(preds,labels)\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torch/_tensor.py:491\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    483\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    484\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    490\u001b[0m     )\n\u001b[0;32m--> 491\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iters = 1000\n",
    "model.train()\n",
    "loss=nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1)\n",
    "\n",
    "for iter in range(iters):\n",
    "\n",
    "    preds = model(data).squeeze(-1)\n",
    "    out = loss(preds,labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    out.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if iter%100==0:\n",
    "        print(f'iter:{iter}\\t|\\tloss:{out.item()}')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 100\t|\tloss: 0.2942263185977936\n",
      "iter: 500\t|\tloss: 0.0005170016083866358\n",
      "iter: 1000\t|\tloss: 0.0005648013320751488\n",
      "iter: 2000\t|\tloss: 0.00045214701094664633\n",
      "iter: 3000\t|\tloss: 0.0004427286039572209\n",
      "iter: 4000\t|\tloss: 0.0005331666325218976\n",
      "iter: 5000\t|\tloss: 0.0005238830344751477\n",
      "iter: 6000\t|\tloss: 0.0006724789855070412\n",
      "iter: 7000\t|\tloss: 0.0005011580651625991\n",
      "iter: 8000\t|\tloss: 0.00048523559235036373\n",
      "iter: 9000\t|\tloss: 0.0005985220777802169\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def scalar_val(tensor):\n",
    "    # assume shape [B,N,4]\n",
    "    eta = torch.tensor([1, -1, -1, -1])\n",
    "    xx = torch.einsum('B N i, i, B N i -> B N', tensor, eta, tensor)\n",
    "    return (xx + xx**2/4) / math.sqrt(21)\n",
    "\n",
    "# Generate data and labels\n",
    "data = torch.randn([1, 10000, 4])\n",
    "labels = scalar_val(data)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, d_in, d_out, bias=True):\n",
    "        super(Block, self).__init__()\n",
    "        self.fc = nn.Linear(d_in, d_out, bias=bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = nn.functional.gelu(x)\n",
    "        return x\n",
    "\n",
    "class CrazyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrazyModel, self).__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            Block(4, 10),\n",
    "            Block(10, 10),\n",
    "            Block(10, 10),\n",
    "            Block(10, 1),\n",
    "        )\n",
    "\n",
    "        self.extand1 = nn.Linear(1,4)\n",
    "        self.bi_lin = nn.Linear(4,4,bias=False)\n",
    "        self.lin = nn.Linear(4,4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        A = torch.einsum('...i,...i->...',self.bi_lin(x),x).unsqueeze(-1)\n",
    "       \n",
    "        x = self.extand1(A)+self.lin(x)\n",
    "        return self.blocks(x)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = CrazyModel()\n",
    "iters = 10000\n",
    "model.train()\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-2,  weight_decay=1e-2)\n",
    "\n",
    "for iter in range(iters):\n",
    "    preds = model(data).squeeze(-1)\n",
    "    out = loss(preds, labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    out.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (iter % 1000 == 0 and iter>0) or iter == 100 or iter ==500:\n",
    "        print(f'iter: {iter}\\t|\\tloss: {out.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-4.2700e-01, -1.0516e-03,  1.5281e-03, -2.5217e-03],\n",
       "        [-2.5560e-03,  4.2480e-01,  2.1524e-02,  1.8373e-03],\n",
       "        [-1.2355e-05, -1.8776e-02,  4.2430e-01, -2.0433e-02],\n",
       "        [ 1.4989e-03, -4.1898e-03,  1.8165e-02,  4.2434e-01]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bi_lin.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 100\t|\tloss: 0.09801734238862991\n",
      "iter: 500\t|\tloss: 0.007461200468242168\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def scalar_val(x):\n",
    "    # assume shape [B,N,4]\n",
    "    shps=x.shape\n",
    "    eta = torch.tensor([1, -1, -1, -1])\n",
    "    x = x.reshape(shps[0],shps[1]//4,4)\n",
    "    xx = torch.einsum('B N i, i, B N i -> B N', x, eta, x)\n",
    "    return (xx + xx**2/4) / math.sqrt(21)\n",
    "\n",
    "# Generate data and labels\n",
    "data = torch.randn([100, 1000*4])  # Using a batch size of 10\n",
    "labels = scalar_val(data)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, d_in, d_out, bias=True):\n",
    "        super(Block, self).__init__()\n",
    "        self.fc = nn.Linear(d_in, d_out, bias=bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = nn.functional.gelu(x)\n",
    "        return x\n",
    "\n",
    "class CrazyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrazyModel, self).__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            Block(4, 10),\n",
    "            Block(10, 10),\n",
    "            Block(10, 10),\n",
    "            Block(10, 1),\n",
    "        )\n",
    "\n",
    "        self.extand1 = nn.Linear(1, 4)\n",
    "        self.bi_lin = nn.Linear(4, 4, bias=False)\n",
    "        self.lin = nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shps=x.shape\n",
    "        x = x.reshape(shps[0],shps[1]//4,4)\n",
    "        \n",
    "        # A = torch.einsum('...i,...i->...', self.bi_lin(x), x).unsqueeze(-1)\n",
    "        # x = self.extand1(A) + self.lin(x)\n",
    "        return self.blocks(x)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = CrazyModel()\n",
    "iters = 1000\n",
    "model.train()\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-2,weight_decay=1e-3)\n",
    "\n",
    "# Define batch size and data loader\n",
    "batch_size = 64\n",
    "dataset = torch.utils.data.TensorDataset(data, labels)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for iter in range(iters):\n",
    "    for batch_data, batch_labels in dataloader:\n",
    "        preds = model(batch_data).squeeze(-1)\n",
    "        out = loss(preds, batch_labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (iter % 1000 == 0 and iter > 0) or iter == 100 or iter == 500:\n",
    "        print(f'iter: {iter}\\t|\\tloss: {out.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(labels.view(-1).detach().numpy(), model(data).view(-1).detach().numpy(),'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lorentz_loss \u001b[38;5;241m=\u001b[39m \u001b[43mLorentzLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m sample \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m],requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Using a batch size of 10\u001b[39;00m\n\u001b[1;32m      4\u001b[0m lorentz_loss(sample,spin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscalar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/Dropbox/Symmetric NN/SymLoss/notebooks/../python/Lorentz_loss.py:41\u001b[0m, in \u001b[0;36mLorentzLoss.__init__\u001b[0;34m(self, device, model)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, device, model):\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mLorentzLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "lorentz_loss = LorentzLoss(model=model,device='cpu')\n",
    "sample = torch.randn([1, 100* 4],requires_grad=True)  # Using a batch size of 10\n",
    "\n",
    "lorentz_loss(sample,spin='scalar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5e-06"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.4/len(data.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import einops\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self,d_in,d_hidden,depth):\n",
    "        super(SimpleNet,self).__init__()\n",
    "\n",
    "        \n",
    "        self.fc_in = nn.Linear(d_in,d_hidden)\n",
    "        self.fcs = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.fcs.append(nn.Linear(d_hidden,d_hidden))\n",
    "            self.fcs.append(nn.ReLU())\n",
    "\n",
    "        self.fcs = nn.Sequential(*self.fcs)\n",
    "\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_hidden,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.fc_in(x)\n",
    "        x = self.fcs(x)\n",
    "        return self.fc_out(x)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn([1000,2])\n",
    "labels = torch.norm(data,2,dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 \tloss: 0.0006657767808064818\n",
      "iter: 10000 \tloss: 2.7011161364498548e-05\n",
      "iter: 20000 \tloss: 5.571808742388384e-06\n",
      "iter: 30000 \tloss: 1.3434574839266133e-06\n",
      "iter: 40000 \tloss: 3.014030482972885e-07\n",
      "iter: 50000 \tloss: 1.0394474969643852e-07\n",
      "iter: 60000 \tloss: 7.645576260983944e-08\n",
      "iter: 70000 \tloss: 8.625303848930344e-08\n",
      "iter: 80000 \tloss: 1.0606062517126702e-07\n",
      "iter: 90000 \tloss: 9.90399158240507e-08\n"
     ]
    }
   ],
   "source": [
    "iters=100000\n",
    "inds = torch.randint(0,10,(iters,1000))\n",
    "inds.shape\n",
    "data_split = data[inds]\n",
    "labels_split = labels[inds]\n",
    "\n",
    "\n",
    "for i, (ins,lbls) in enumerate(zip(data_split, labels_split)):\n",
    "    \n",
    "    preds = model(ins).view(-1)\n",
    "    loss = criterion(preds,lbls.view(-1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i%10000==0:\n",
    "        print(f'iter: {i} \\tloss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Data\n",
    "data = torch.randn([2000, 2])\n",
    "labels = torch.norm(data, 2, dim=-1, keepdim=True)  # Ensuring labels have the same shape\n",
    "labels += labels**2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([908, 2])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data[labels.view(-1)>2,:]\n",
    "labels=labels[labels.view(-1)>2]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, lr: [0.00032000210691979225], Loss: 17.15064239501953\n",
      "Epoch: 1001, lr: [0.0022446467459712105], Loss: 0.00806010328233242\n",
      "Epoch: 2001, lr: [0.0060858031641032855], Loss: 0.002568536438047886\n",
      "Epoch: 3001, lr: [0.007999998391214307], Loss: 0.002234270330518484\n",
      "Epoch: 4001, lr: [0.0076029525015640954], Loss: 0.003955607768148184\n",
      "Epoch: 5001, lr: [0.006493565280157327], Loss: 0.0014279878232628107\n",
      "Epoch: 6001, lr: [0.004891564471935003], Loss: 0.0013319478603079915\n",
      "Epoch: 7001, lr: [0.0031142459842161186], Loss: 0.0012666907859966159\n",
      "Epoch: 8001, lr: [0.001513629540874196], Loss: 0.001044192467816174\n",
      "Epoch: 9001, lr: [0.00040673685878554316], Loss: 0.0008776861941441894\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNet(2,8,8)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-4,weight_decay=3e-4,momentum=0.6)\n",
    "# Training loop\n",
    "num_epochs = 10000\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                       max_lr = 8e-3, # Upper learning rate boundaries in the cycle for each parameter group\n",
    "                       \n",
    "                       total_steps=num_epochs,\n",
    "                       div_factor = 25,\n",
    "                       final_div_factor = 25,\n",
    "                    #    steps_per_epoch = 8, # The number of steps per epoch to train for.\n",
    "                    #    epochs = 4, # The number of epochs to train for.\n",
    "                       anneal_strategy = 'cos') # Specifies the annealing strategy\n",
    "\n",
    "\n",
    "\n",
    "# torch.\n",
    "model.train()\n",
    "\n",
    "\n",
    "\n",
    "# Creating TensorDataset\n",
    "dataset = TensorDataset(data, labels)\n",
    "\n",
    "# Creating DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=500, shuffle=True)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (ins, lbls) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        preds = model(ins).view(-1)\n",
    "        loss = criterion(preds, lbls.view(-1))\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % 1000 == 0:  # Adjust print frequency as needed\n",
    "        print(f'Epoch: {epoch+1}, lr: {scheduler.get_last_lr()}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(labels.view(-1).detach().numpy(),model(data).view(-1).detach().numpy(),'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 5]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[2,5,4]\n",
    "a.sort()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "data_g = data.clone().detach().requires_grad_(True)\n",
    "outs = model(data_g)\n",
    "grads = torch.autograd.grad(outputs=outs,inputs=data_g,grad_outputs=torch.ones_like(outs))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-3.7164e-03,  7.0416e-01],\n",
       "         [-7.1003e-01,  2.0667e-04]]),\n",
       " tensor([ 0.1575,  9.1362,  9.8799, 19.2056]))"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import einops\n",
    "data_g.requires_grad_=False\n",
    "gx=einops.rearrange(torch.einsum('ai,aj->aij',data_g,grads), 'a i j -> a (i j)')\n",
    "gxgx = torch.einsum('ai,aj->aij',gx,gx)\n",
    "\n",
    "\n",
    "\n",
    "gxgx_mean = torch.mean(gxgx,dim=0).detach()\n",
    "gxgx_mean\n",
    "\n",
    "eig = torch._linalg_eigh(gxgx_mean)\n",
    "eig.eigenvectors[:,0].view(2,2), eig.eigenvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig.eigenvectors[:,0] @ eig.eigenvectors[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=9, out_features=9, bias=False)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = nn.Linear(len(gxv[0]),len(gxv[0]),bias=False)\n",
    "mod.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(mod.parameters(), lr=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([1000000,2],requires_grad=True)\n",
    "y = torch.norm(x,2,keepdim = True,dim = -1)\n",
    "g = torch.autograd.grad(y,x,torch.ones_like(y))[0].detach()\n",
    "x = x.detach()\n",
    "\n",
    "xg = einops.rearrange(torch.einsum('ij, ik ->ijk',x,g), 'i j k -> i (j k)')\n",
    "\n",
    "# xg.requires_grad_=False\n",
    "xgxg = torch.einsum('ij, ik -> ijk',xg,xg)\n",
    "xgxg_mean = torch.mean(xgxg,dim=0)\n",
    "eig=torch.linalg.eig(xgxg_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000, 4, 4])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgxg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9779,  0.0000, -0.0000,  0.7249])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xgxg_mean @ torch.real(eig.eigenvectors[:,-1]))/torch.real(eig.eigenvectors[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.2282e-01, -1.0537e-07,  1.2644e-07,  6.0522e-01])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig=torch._linalg_eigh(xgxg_mean)\n",
    "\n",
    "(xgxg_mean @ (eig.eigenvectors[:,0]) )/eig.eigenvectors[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8572e-08, -7.0711e-01],\n",
       "        [ 7.0711e-01,  3.1325e-08]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev1=eig.eigenvectors[:,0]\n",
    "ev1.view(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(torch.norm(torch.randn([100000,300]),2,dim=-1)/math.sqrt(300),50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(299.9980)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.norm(torch.randn([1000000,300]),2,dim=-1)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'101101110011100'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin(23452)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lasso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
