{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import grad\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append('../python')\n",
    "\n",
    "import models\n",
    "from models import FashionCNN, simpleNN\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision \n",
    "import torchvision.transforms as tt\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "\n",
    "data_dir='../data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "# run below only if you want to claculate the mean and std, but I already did\n",
    "# print(\"Downloading FashionMNIST data...\")\n",
    "# fashion_train = FashionMNIST(data_dir, train=True, download=True)\n",
    "fashion_test = FashionMNIST(data_dir, train=False, download=True)\n",
    "\n",
    "# train_long=torch.stack([tt.ToTensor()(im).view(-1) for im,_ in fashion_train])\n",
    "# test_long=torch.stack([tt.ToTensor()(im).view(-1) for im,_ in fashion_test])\n",
    "\n",
    "\n",
    "# train_mean = torch.mean(train_long)\n",
    "# train_std = torch.std(train_long)\n",
    "# test_mean = torch.mean(test_long)\n",
    "# test_std = torch.std(test_long)\n",
    "\n",
    "train_mean = 0.2860\n",
    "train_std = 0.3530\n",
    "test_mean = 0.2868\n",
    "test_std = 0.3524\n",
    "\n",
    "test_transform=tt.Compose([\n",
    "    tt.ToTensor(), \n",
    "    tt.Normalize(mean=(test_mean,),std=(test_std,))\n",
    "])\n",
    "\n",
    "train_null_transform = tt.Compose([\n",
    "    tt.ToTensor(), \n",
    "    tt.Normalize(mean=(train_mean,),std=(train_std,))\n",
    "])\n",
    "\n",
    "train_trans_transform = tt.Compose([\n",
    "    tt.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n",
    "    tt.ToTensor(), \n",
    "    tt.Normalize(mean=(train_mean,),std=(train_std,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(fashion_test[0][0])\n",
    "plt.show()\n",
    "plt.imshow(tt.RandomAffine(degrees=0, translate=(0.5, 0.5))(fashion_test[0][0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     28\u001b[0m epoc_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img,lbl \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     30\u001b[0m     img\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m     lbl\u001b[38;5;241m=\u001b[39mlbl\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torchvision/transforms/transforms.py:1536\u001b[0m, in \u001b[0;36mRandomAffine.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1532\u001b[0m img_size \u001b[38;5;241m=\u001b[39m [width, height]  \u001b[38;5;66;03m# flip for keeping BC on get_params call\u001b[39;00m\n\u001b[1;32m   1534\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegrees, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshear, img_size)\n\u001b[0;32m-> 1536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torchvision/transforms/functional.py:1236\u001b[0m, in \u001b[0;36maffine\u001b[0;34m(img, angle, translate, scale, shear, interpolation, fill, center)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     matrix \u001b[38;5;241m=\u001b[39m _get_inverse_affine_matrix(center, angle, translate, scale, shear)\n\u001b[1;32m   1235\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m-> 1236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1238\u001b[0m center_f \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m]\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m center \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torchvision/transforms/_functional_pil.py:295\u001b[0m, in \u001b[0;36maffine\u001b[0;34m(img, matrix, interpolation, fill)\u001b[0m\n\u001b[1;32m    293\u001b[0m output_size \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39msize\n\u001b[1;32m    294\u001b[0m opts \u001b[38;5;241m=\u001b[39m _parse_fill(fill, img)\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAFFINE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/PIL/Image.py:2713\u001b[0m, in \u001b[0;36mImage.transform\u001b[0;34m(self, size, method, data, resample, fill, fillcolor)\u001b[0m\n\u001b[1;32m   2709\u001b[0m         im\u001b[38;5;241m.\u001b[39m__transformer(\n\u001b[1;32m   2710\u001b[0m             box, \u001b[38;5;28mself\u001b[39m, Transform\u001b[38;5;241m.\u001b[39mQUAD, quad, resample, fillcolor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2711\u001b[0m         )\n\u001b[1;32m   2712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2713\u001b[0m     \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__transformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2714\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfillcolor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   2715\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/PIL/Image.py:2796\u001b[0m, in \u001b[0;36mImage.__transformer\u001b[0;34m(self, box, image, method, data, resample, fill)\u001b[0m\n\u001b[1;32m   2793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2794\u001b[0m     resample \u001b[38;5;241m=\u001b[39m Resampling\u001b[38;5;241m.\u001b[39mNEAREST\n\u001b[0;32m-> 2796\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LR=3e-3\n",
    "WD=3e-3\n",
    "epochs=2\n",
    "device='mps'\n",
    "\n",
    "torch.manual_seed(56420)\n",
    "\n",
    "torch.manual_seed(56420)\n",
    "fashion_train = FashionMNIST(data_dir, train=True, download=True, transform=train_trans_transform)\n",
    "fashion_test = FashionMNIST(data_dir, train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_loader=DataLoader(fashion_train,shuffle=True, batch_size=128)\n",
    "test_loader=DataLoader(fashion_test,shuffle=False, batch_size=128)\n",
    "\n",
    "\n",
    "model = FashionCNN()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "model = FashionCNN()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    epoc_loss=0.0\n",
    "    for img,lbl in train_loader:\n",
    "        img=img.to(device)\n",
    "        lbl=lbl.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(img)\n",
    "        loss = F.cross_entropy(pred,lbl)\n",
    "        epoc_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    epoc_loss/=len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    epoch_val_loss=0.0\n",
    "    correct=0.0\n",
    "    total=0\n",
    "    for img,lbl in test_loader:\n",
    "        img=img.to(device)\n",
    "        lbl=lbl.to(device)\n",
    "        pred = model(img)\n",
    "        loss = F.cross_entropy(pred,lbl)\n",
    "        epoch_val_loss+=loss.item()\n",
    "        \n",
    "        \n",
    "        correct+= (pred.argmax(dim=1) == lbl).type(torch.float).sum().item()\n",
    "        total += lbl.size(0)\n",
    "\n",
    "        \n",
    "    epoch_val_loss/=len(test_loader)\n",
    "    correct/=total\n",
    "    print(f'epoch: {epoch} | train loss: {epoc_loss} | val loss: {epoch_val_loss} | acc: {100*correct:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the fun part. We want to penalize violation of translation invariance instead of augmenting the data to achieve translation invariance.  The way we go about it is as follows: Assume that under an infinitesimal translation the input changes from $X$ to $X + \\epsilon M\\cdot X$, where $M$ is the generator of translations. We want the output to remain unchanged under this transformation. This means that the output $F(X)=F(X+\\epsilon M\\cdot X)\\sim F(X) + \\epsilon [\\nabla_X F(X)]^T\\cdot M\\cdot X$. For image translations, it is simpler to think of vertical and horizontal translations separately. Horizontal translations operate only on the rows of the image, and vertical translations operate only on the columns of the image. $M$ acts as a discrete derivative, namely $M$ takes the form\n",
    "\n",
    "$$\n",
    "M_{\\rm hor} = \\frac{1}{2}\\begin{bmatrix}\n",
    "-2 & 2 & 0 & \\cdots & 0 \\\\\n",
    "-1 & 0 & 1 & \\ddots & \\vdots \\\\\n",
    "0 & -1 & 0 & 1 & 0 \\\\\n",
    "\\vdots & \\ddots & \\ddots & \\ddots & 2 \\\\\n",
    "0 & \\cdots & 0 & -2 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The vertical translation operator $M_{\\rm ver}$ is the transpose of $M_{\\rm hor}$. The penalty term is then given by\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\rm sym} = \\frac{\\lambda}{2}\\left[\\left\\|\\nabla_X F(X)\\cdot M_{\\rm hor}\\cdot X\\right\\|_2^2 + \\left\\|\\nabla_X F(X)\\cdot M_{\\rm ver}\\cdot X\\right\\|_2^2\\right]\n",
    "$$\n",
    "\n",
    "In practice, it is easy to construct $M_{\\rm hor}.X$ and $M_{\\rm ver}.X$ using broadcasting.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Modified loss thingy \n",
    "def get_losses(model,img,lbl):\n",
    "    \n",
    "    \n",
    "    dif_v=torch.zeros_like(img)\n",
    "    dif_v[:,:,1:-1]=img[:,:,2:]-img[:,:,:-2]\n",
    "    dif_v/=2.0      \n",
    "    dif_v[:,:,0]=img[:,:,1]-img[:,:,0]\n",
    "    dif_v[:,:,-1]=img[:,:,-1]-img[:,:,-2]\n",
    "\n",
    "    dif_h=torch.zeros_like(img)\n",
    "    dif_h[:,:,:,1:-1]=img[:,:,:,2:]-img[:,:,:,:-2]\n",
    "    dif_h/=2.0\n",
    "    dif_h[:,:,:,0]=img[:,:,:,1]-img[:,:,:,0]\n",
    "    dif_h[:,:,:,-1]=img[:,:,:,-1]-img[:,:,:,-2]\n",
    "\n",
    "    img.requires_grad=True\n",
    "    out=model(img)\n",
    "    loss=F.cross_entropy(out,lbl)\n",
    "    \n",
    "    grads, =torch.autograd.grad(out,img,grad_outputs=torch.ones_like(out),create_graph=True,allow_unused=True)\n",
    "    # img.requires_grad=False\n",
    "    h_term=torch.einsum('ijkl,ijkl->ij',grads,dif_h).squeeze() #[0] since the shape is batch*channel*H*W, and we have a single channel\n",
    "    v_term=torch.einsum('ijkl,ijkl->ij',grads,dif_v).squeeze()\n",
    "    sym_loss=(h_term**2+v_term**2).mean()\n",
    "    \n",
    "    return loss,sym_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | train loss: 0.8288178387989622 | val loss: 0.5319499520561363 | acc: 82.28\n",
      "epoch: 1 | train loss: 0.5871578880718776 | val loss: 0.505652428427829 | acc: 82.67\n",
      "epoch: 2 | train loss: 0.5500655622243373 | val loss: 0.4919432801536367 | acc: 83.98\n",
      "epoch: 3 | train loss: 0.5313281301877646 | val loss: 0.49400046807301196 | acc: 80.81\n",
      "epoch: 4 | train loss: 0.5161819858337516 | val loss: 0.4659710579280612 | acc: 85.12\n",
      "epoch: 5 | train loss: 0.506743979606547 | val loss: 0.4401211553736578 | acc: 85.73\n",
      "epoch: 6 | train loss: 0.4964753823366755 | val loss: 0.46515561357329166 | acc: 83.95\n",
      "epoch: 7 | train loss: 0.489790220250453 | val loss: 0.4527797321730022 | acc: 84.74\n",
      "epoch: 8 | train loss: 0.48777061167047986 | val loss: 0.42891276637210124 | acc: 85.67\n",
      "epoch: 9 | train loss: 0.4807228045041627 | val loss: 0.4329388730133636 | acc: 85.42\n"
     ]
    }
   ],
   "source": [
    "LR=3e-3\n",
    "WD=3e-3\n",
    "epochs=10\n",
    "device='mps'\n",
    "\n",
    "\n",
    "torch.manual_seed(56420)\n",
    "\n",
    "torch.manual_seed(56420)\n",
    "fashion_train = FashionMNIST(data_dir, train=True, download=True, transform=train_trans_transform)\n",
    "fashion_test = FashionMNIST(data_dir, train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_loader=DataLoader(fashion_train,shuffle=True, batch_size=128)\n",
    "test_loader=DataLoader(fashion_test,shuffle=False, batch_size=128)\n",
    "\n",
    "model = FashionCNN()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    epoc_loss=0.0\n",
    "    for img,lbl in train_loader:\n",
    "        img=img.to(device)\n",
    "        lbl=lbl.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss, symm_loss = get_losses(model,img,lbl)\n",
    "        \n",
    "        epoc_loss+=loss.item()\n",
    "        loss+=0.051*symm_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    epoc_loss/=len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    epoch_val_loss=0.0\n",
    "    correct=0.0\n",
    "    total=0\n",
    "    for img,lbl in test_loader:\n",
    "        img=img.to(device)\n",
    "        lbl=lbl.to(device)\n",
    "        pred = model(img)\n",
    "        loss = F.cross_entropy(pred,lbl)\n",
    "        epoch_val_loss+=loss.item()\n",
    "        \n",
    "        \n",
    "        correct+= (pred.argmax(dim=1) == lbl).type(torch.float).sum().item()\n",
    "        total += lbl.size(0)\n",
    "\n",
    "        \n",
    "    epoch_val_loss/=len(test_loader)\n",
    "    correct/=total\n",
    "    print(f'epoch: {epoch} | train loss: {epoc_loss} | val loss: {epoch_val_loss} | acc: {100*correct:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lasso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
