{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import grad\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append('../python')\n",
    "\n",
    "import models\n",
    "from models import FashionCNN, simpleNN\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision \n",
    "import torchvision.transforms as tt\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "\n",
    "data_dir='../data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "# run below only if you want to claculate the mean and std, but I already did\n",
    "# print(\"Downloading FashionMNIST data...\")\n",
    "# fashion_train = FashionMNIST(data_dir, train=True, download=True)\n",
    "fashion_test = FashionMNIST(data_dir, train=False, download=True)\n",
    "\n",
    "# train_long=torch.stack([tt.ToTensor()(im).view(-1) for im,_ in fashion_train])\n",
    "# test_long=torch.stack([tt.ToTensor()(im).view(-1) for im,_ in fashion_test])\n",
    "\n",
    "\n",
    "# train_mean = torch.mean(train_long)\n",
    "# train_std = torch.std(train_long)\n",
    "# test_mean = torch.mean(test_long)\n",
    "# test_std = torch.std(test_long)\n",
    "\n",
    "train_mean = 0.2860\n",
    "train_std = 0.3530\n",
    "test_mean = 0.2868\n",
    "test_std = 0.3524\n",
    "\n",
    "pad_affine_transform=tt.Compose([\n",
    "    tt.Pad([10,10]),\n",
    "    tt.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n",
    "    tt.ToTensor(), \n",
    "    tt.Normalize(mean=(test_mean,),std=(test_std,))\n",
    "])\n",
    "\n",
    "pad_null_transform = tt.Compose([\n",
    "    tt.Pad([10,10]),\n",
    "    tt.ToTensor(), \n",
    "    tt.Normalize(mean=(train_mean,),std=(train_std,))\n",
    "])\n",
    "\n",
    "train_trans_transform = tt.Compose([\n",
    "    tt.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n",
    "    tt.ToTensor(), \n",
    "    tt.Normalize(mean=(train_mean,),std=(train_std,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 48, 48])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.ToTensor()(tt.Pad([10,10])(fashion_test[0][0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(fashion_test[0][0])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(tt.RandomAffine(degrees=0, translate=(0.5, 0.5))(fashion_test[0][0]))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(tt.Resize([28,28])(tt.Pad([10,10])(fashion_test[0][0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | train loss: 2.1649000548096353 | val loss: 2.72410935993436 | acc: 20.43\n",
      "epoch: 1 | train loss: 1.675096640963036 | val loss: 3.5588146040711224 | acc: 20.92\n",
      "epoch: 2 | train loss: 1.4607089834172589 | val loss: 2.8850105472757845 | acc: 26.97\n",
      "epoch: 3 | train loss: 1.3774746702169813 | val loss: 3.572667441790617 | acc: 24.91\n",
      "epoch: 4 | train loss: 1.1707292131777765 | val loss: 3.0493041548547866 | acc: 26.39\n",
      "epoch: 5 | train loss: 1.1104587463936064 | val loss: 3.1269785029978694 | acc: 26.62\n",
      "epoch: 6 | train loss: 1.092894517409522 | val loss: 2.4184396040590506 | acc: 28.16\n",
      "epoch: 7 | train loss: 1.0722820226317529 | val loss: 2.880046044723897 | acc: 27.33\n",
      "epoch: 8 | train loss: 1.0000918651186328 | val loss: 2.884186611899847 | acc: 27.96\n",
      "epoch: 9 | train loss: 0.9658284666441651 | val loss: 2.9468550802786138 | acc: 28.29\n",
      "epoch: 10 | train loss: 0.951621633729955 | val loss: 2.924712413473974 | acc: 26.93\n",
      "epoch: 11 | train loss: 0.9367483315437333 | val loss: 2.6555900483191768 | acc: 27.34\n",
      "epoch: 12 | train loss: 0.931801103198452 | val loss: 3.196381813363184 | acc: 27.49\n",
      "epoch: 13 | train loss: 0.9299661712859993 | val loss: 3.0568352711351614 | acc: 27.93\n",
      "epoch: 14 | train loss: 0.927212242378609 | val loss: 3.121765357029589 | acc: 27.08\n",
      "epoch: 15 | train loss: 0.9194687706575211 | val loss: 3.0403065319302716 | acc: 28.27\n",
      "epoch: 16 | train loss: 0.9112188023036477 | val loss: 3.09168444555017 | acc: 28.21\n",
      "epoch: 17 | train loss: 0.9038542456972574 | val loss: 3.4121168353889564 | acc: 27.76\n",
      "epoch: 18 | train loss: 0.9021588806658666 | val loss: 3.265947375116469 | acc: 27.52\n",
      "epoch: 19 | train loss: 0.8971279229182424 | val loss: 2.916306166709224 | acc: 27.99\n"
     ]
    }
   ],
   "source": [
    "LR=5e-3\n",
    "WD=3e-3\n",
    "epochs=20\n",
    "device='mps'\n",
    "\n",
    "\n",
    "torch.manual_seed(56420)\n",
    "\n",
    "fashion_train = FashionMNIST(data_dir, train=True, download=True, transform=pad_null_transform)\n",
    "fashion_test = FashionMNIST(data_dir, train=False, download=True, transform=pad_affine_transform)\n",
    "\n",
    "train_loader=DataLoader(fashion_train,shuffle=True, batch_size=128)\n",
    "test_loader=DataLoader(fashion_test,shuffle=False, batch_size=128)\n",
    "\n",
    "\n",
    "model = FashionCNN()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "model = FashionCNN()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    epoc_loss=0.0\n",
    "    for img,lbl in train_loader:\n",
    "        img=img.to(device)\n",
    "        lbl=lbl.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(img)\n",
    "        loss = F.cross_entropy(pred,lbl)\n",
    "        epoc_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    epoc_loss/=len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    epoch_val_loss=0.0\n",
    "    correct=0.0\n",
    "    total=0\n",
    "    for img,lbl in test_loader:\n",
    "        img=img.to(device)\n",
    "        lbl=lbl.to(device)\n",
    "        pred = model(img)\n",
    "        loss = F.cross_entropy(pred,lbl)\n",
    "        epoch_val_loss+=loss.item()\n",
    "        \n",
    "        \n",
    "        correct+= (pred.argmax(dim=1) == lbl).type(torch.float).sum().item()\n",
    "        total += lbl.size(0)\n",
    "\n",
    "        \n",
    "    epoch_val_loss/=len(test_loader)\n",
    "    correct/=total\n",
    "    print(f'epoch: {epoch} | train loss: {epoc_loss} | val loss: {epoch_val_loss} | acc: {100*correct:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the fun part. We want to penalize violation of translation invariance instead of augmenting the data to achieve translation invariance.  The way we go about it is as follows: Assume that under an infinitesimal translation the input changes from $X$ to $X + \\epsilon M\\cdot X$, where $M$ is the generator of translations. We want the output to remain unchanged under this transformation. This means that the output $F(X)=F(X+\\epsilon M\\cdot X)\\sim F(X) + \\epsilon [\\nabla_X F(X)]^T\\cdot M\\cdot X$. For image translations, it is simpler to think of vertical and horizontal translations separately. Horizontal translations operate only on the rows of the image, and vertical translations operate only on the columns of the image. $M$ acts as a discrete derivative, namely $M$ takes the form\n",
    "\n",
    "$$\n",
    "M_{\\rm hor} = \\frac{1}{2}\\begin{bmatrix}\n",
    "-2 & 2 & 0 & \\cdots & 0 \\\\\n",
    "-1 & 0 & 1 & \\ddots & \\vdots \\\\\n",
    "0 & -1 & 0 & 1 & 0 \\\\\n",
    "\\vdots & \\ddots & \\ddots & \\ddots & 2 \\\\\n",
    "0 & \\cdots & 0 & -2 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The vertical translation operator $M_{\\rm ver}$ is the transpose of $M_{\\rm hor}$. The penalty term is then given by\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\rm sym} = \\frac{\\lambda}{2}\\left[\\left\\|\\nabla_X F(X)\\cdot M_{\\rm hor}\\cdot X\\right\\|_2^2 + \\left\\|\\nabla_X F(X)\\cdot M_{\\rm ver}\\cdot X\\right\\|_2^2\\right]\n",
    "$$\n",
    "\n",
    "In practice, it is easy to construct $M_{\\rm hor}.X$ and $M_{\\rm ver}.X$ using broadcasting.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Modified loss thingy \n",
    "def get_losses(model,img,lbl):\n",
    "    \n",
    "    \n",
    "    dif_v=torch.zeros_like(img)\n",
    "    dif_v[:,:,1:-1]=img[:,:,2:]-img[:,:,:-2]\n",
    "    dif_v/=2.0      \n",
    "    dif_v[:,:,0]=img[:,:,1]-img[:,:,0]\n",
    "    dif_v[:,:,-1]=img[:,:,-1]-img[:,:,-2]\n",
    "\n",
    "    dif_h=torch.zeros_like(img)\n",
    "    dif_h[:,:,:,1:-1]=img[:,:,:,2:]-img[:,:,:,:-2]\n",
    "    dif_h/=2.0\n",
    "    dif_h[:,:,:,0]=img[:,:,:,1]-img[:,:,:,0]\n",
    "    dif_h[:,:,:,-1]=img[:,:,:,-1]-img[:,:,:,-2]\n",
    "\n",
    "    img.requires_grad=True\n",
    "    out=model(img)\n",
    "    loss=F.cross_entropy(out,lbl)\n",
    "    \n",
    "    grads, =torch.autograd.grad(out,img,grad_outputs=torch.ones_like(out),create_graph=True,allow_unused=True)\n",
    "    # img.requires_grad=False\n",
    "    h_term=torch.einsum('ijkl,ijkl->ij',grads,dif_h).squeeze() #[0] since the shape is batch*channel*H*W, and we have a single channel\n",
    "    v_term=torch.einsum('ijkl,ijkl->ij',grads,dif_v).squeeze()\n",
    "    sym_loss=(h_term**2+v_term**2).mean()\n",
    "    \n",
    "    return loss,sym_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | train loss: 2.3024546551043543 | val loss: 2.3002583437328097 | acc: 10.25\n",
      "epoch: 1 | train loss: 2.3025851249694824 | val loss: 2.3024357421488704 | acc: 10.19\n",
      "epoch: 2 | train loss: 2.3025851249694824 | val loss: 2.3017111911049373 | acc: 10.21\n",
      "epoch: 3 | train loss: 2.3025851249694824 | val loss: 2.3003433324113676 | acc: 10.19\n",
      "epoch: 4 | train loss: 2.3025851249694824 | val loss: 2.3014930049075355 | acc: 10.16\n",
      "epoch: 5 | train loss: 2.3025851249694824 | val loss: 2.3019377008269104 | acc: 10.20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m     epoc_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     34\u001b[0m     loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.051\u001b[39m\u001b[38;5;241m*\u001b[39msymm_loss\n\u001b[0;32m---> 35\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     37\u001b[0m epoc_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torch/_tensor.py:491\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    483\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    484\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    490\u001b[0m     )\n\u001b[0;32m--> 491\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LR=3e-3\n",
    "WD=3e-3\n",
    "epochs=10\n",
    "device='mps'\n",
    "\n",
    "\n",
    "torch.manual_seed(56420)\n",
    "\n",
    "torch.manual_seed(56420)\n",
    "fashion_train = FashionMNIST(data_dir, train=True, download=True, transform=pad_null_transform)\n",
    "fashion_test = FashionMNIST(data_dir, train=False, download=True, transform=pad_affine_transform)\n",
    "\n",
    "train_loader=DataLoader(fashion_train,shuffle=True, batch_size=128)\n",
    "test_loader=DataLoader(fashion_test,shuffle=False, batch_size=128)\n",
    "\n",
    "model = FashionCNN()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    epoc_loss=0.0\n",
    "    for img,lbl in train_loader:\n",
    "        img=img.to(device)\n",
    "        lbl=lbl.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss, symm_loss = get_losses(model,img,lbl)\n",
    "        \n",
    "        epoc_loss+=loss.item()\n",
    "        loss+=0.051*symm_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    epoc_loss/=len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    epoch_val_loss=0.0\n",
    "    correct=0.0\n",
    "    total=0\n",
    "    for img,lbl in test_loader:\n",
    "        img=img.to(device)\n",
    "        lbl=lbl.to(device)\n",
    "        pred = model(img)\n",
    "        loss = F.cross_entropy(pred,lbl)\n",
    "        epoch_val_loss+=loss.item()\n",
    "        \n",
    "        \n",
    "        correct+= (pred.argmax(dim=1) == lbl).type(torch.float).sum().item()\n",
    "        total += lbl.size(0)\n",
    "\n",
    "        \n",
    "    epoch_val_loss/=len(test_loader)\n",
    "    correct/=total\n",
    "    print(f'epoch: {epoch} | train loss: {epoc_loss} | val loss: {epoch_val_loss} | acc: {100*correct:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | train loss: 2.3024546551043543 | val loss: 2.3002583437328097 | acc: 10.25\n",
      "epoch: 1 | train loss: 2.3025851249694824 | val loss: 2.3024357421488704 | acc: 10.19\n",
      "epoch: 2 | train loss: 2.3025851249694824 | val loss: 2.3017111911049373 | acc: 10.21\n",
      "epoch: 3 | train loss: 2.3025851249694824 | val loss: 2.3003433324113676 | acc: 10.19\n",
      "epoch: 4 | train loss: 2.3025851249694824 | val loss: 2.3014930049075355 | acc: 10.16\n",
      "epoch: 5 | train loss: 2.3025851249694824 | val loss: 2.3019377008269104 | acc: 10.20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[35], line 35\u001b[0m\n",
      "\u001b[1;32m     33\u001b[0m     epoc_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;32m     34\u001b[0m     loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.051\u001b[39m\u001b[38;5;241m*\u001b[39msymm_loss\n",
      "\u001b[0;32m---> 35\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     36\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[1;32m     37\u001b[0m epoc_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torch/_tensor.py:491\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n",
      "\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n",
      "\u001b[1;32m    483\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n",
      "\u001b[1;32m    484\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    489\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n",
      "\u001b[1;32m    490\u001b[0m     )\n",
      "\u001b[0;32m--> 491\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n",
      "\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/lasso/lib/python3.8/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n",
      "\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n",
      "\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n",
      "\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n",
      "\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n",
      "\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LR=3e-3\n",
    "WD=3e-3\n",
    "epochs=10\n",
    "device='mps'\n",
    "\n",
    "\n",
    "torch.manual_seed(56420)\n",
    "\n",
    "torch.manual_seed(56420)\n",
    "fashion_train = FashionMNIST(data_dir, train=True, download=True, transform=pad_null_transform)\n",
    "fashion_test = FashionMNIST(data_dir, train=False, download=True, transform=pad_affine_transform)\n",
    "\n",
    "train_loader=DataLoader(fashion_train,shuffle=True, batch_size=128)\n",
    "test_loader=DataLoader(fashion_test,shuffle=False, batch_size=128)\n",
    "\n",
    "model = FashionCNN()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    epoc_loss=0.0\n",
    "    for img,lbl in train_loader:\n",
    "        img=img.to(device)\n",
    "        lbl=lbl.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss, symm_loss = get_losses(model,img,lbl)\n",
    "        \n",
    "        epoc_loss+=loss.item()\n",
    "        loss+=0.051*symm_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    epoc_loss/=len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    epoch_val_loss=0.0\n",
    "    correct=0.0\n",
    "    total=0\n",
    "    for img,lbl in test_loader:\n",
    "        img=img.to(device)\n",
    "        lbl=lbl.to(device)\n",
    "        pred = model(img)\n",
    "        loss = F.cross_entropy(pred,lbl)\n",
    "        epoch_val_loss+=loss.item()\n",
    "        \n",
    "        \n",
    "        correct+= (pred.argmax(dim=1) == lbl).type(torch.float).sum().item()\n",
    "        total += lbl.size(0)\n",
    "\n",
    "        \n",
    "    epoch_val_loss/=len(test_loader)\n",
    "    correct/=total\n",
    "    print(f'epoch: {epoch} | train loss: {epoc_loss} | val loss: {epoch_val_loss} | acc: {100*correct:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lasso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
